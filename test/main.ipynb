{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python392jvsc74a57bd0e922dd073470bdcc017ae3abd31d6491d6ed7bf31c1d559806e5511bfea88b81",
   "display_name": "Python 3.9.2 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "e922dd073470bdcc017ae3abd31d6491d6ed7bf31c1d559806e5511bfea88b81"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymorphy2\n",
    "#from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/covid_tweets.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1491177, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 109
    }
   ],
   "source": [
    "# размеры данных\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def lemmatize(text: str) -> list:\n",
    "    words = text.split() # разбиваем текст на слова\n",
    "    res = list()\n",
    "    for word in words:\n",
    "        p = morph.parse(word)[0]\n",
    "        res.append(p.normal_form)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# получаем список слов\n",
    "res = []\n",
    "for text in df['text'].head(15):\n",
    "    temp_list_of_words = lemmatize(text)\n",
    "    for word in temp_list_of_words:\n",
    "        res.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# получаем список стоп-слов\n",
    "with open('./data/stopwords-ru.txt', 'r', encoding='utf-8') as f:\n",
    "    stopwords = [str(i) for i in f.read().split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удаляем стоп-слова если таковые есть\n",
    "for word in res:\n",
    "    if word in stopwords:\n",
    "        res.remove(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in res:\n",
    "    if res.count(word) < 5:\n",
    "        res.remove(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# словарь с указанием сколько раз встречается каждое слово\n",
    "words_counter = Counter()\n",
    "for word in res:\n",
    "    words_counter[word] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('word_frequency.csv','w', encoding='utf-8') as csvfile:\n",
    "    columns = ['word', 'frequency']\n",
    "    writer=csv.writer(csvfile)\n",
    "    writer.writerow(columns)\n",
    "    writer.writerows(words_counter.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}